{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true,
    "execution": {
     "iopub.execute_input": "2024-01-22T05:25:53.982831Z",
     "iopub.status.busy": "2024-01-22T05:25:53.982078Z",
     "iopub.status.idle": "2024-01-22T05:26:51.132298Z",
     "shell.execute_reply": "2024-01-22T05:26:51.130313Z",
     "shell.execute_reply.started": "2024-01-22T05:25:53.982798Z"
    },
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'SchemaInferenceError' from 'datasets.arrow_writer' (/opt/conda/lib/python3.10/site-packages/datasets/arrow_writer.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pipeline\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SFTTrainer\n\u001b[1;32m     16\u001b[0m device \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available()\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     22\u001b[0m )\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUsing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m device\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trl/__init__.py:23\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimport_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      9\u001b[0m     is_bitsandbytes_available,\n\u001b[1;32m     10\u001b[0m     is_diffusers_available,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     is_xpu_available,\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     17\u001b[0m     AutoModelForCausalLMWithValueHead,\n\u001b[1;32m     18\u001b[0m     AutoModelForSeq2SeqLMWithValueHead,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     setup_chat_format,\n\u001b[1;32m     22\u001b[0m )\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtrainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     24\u001b[0m     DataCollatorForCompletionOnlyLM,\n\u001b[1;32m     25\u001b[0m     DPOTrainer,\n\u001b[1;32m     26\u001b[0m     IterativeSFTTrainer,\n\u001b[1;32m     27\u001b[0m     PPOConfig,\n\u001b[1;32m     28\u001b[0m     PPOTrainer,\n\u001b[1;32m     29\u001b[0m     RewardConfig,\n\u001b[1;32m     30\u001b[0m     RewardTrainer,\n\u001b[1;32m     31\u001b[0m     SFTTrainer,\n\u001b[1;32m     32\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_diffusers_available():\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     37\u001b[0m         DDPOPipelineOutput,\n\u001b[1;32m     38\u001b[0m         DDPOSchedulerOutput,\n\u001b[1;32m     39\u001b[0m         DDPOStableDiffusionPipeline,\n\u001b[1;32m     40\u001b[0m         DefaultDDPOStableDiffusionPipeline,\n\u001b[1;32m     41\u001b[0m     )\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trl/trainer/__init__.py:45\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreward_config\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RewardConfig\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreward_trainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RewardTrainer, compute_accuracy\n\u001b[0;32m---> 45\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msft_trainer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SFTTrainer\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/trl/trainer/sft_trainer.py:23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnn\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dataset\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrow_writer\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SchemaInferenceError\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbuilder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DatasetGenerationError\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     26\u001b[0m     AutoModelForCausalLM,\n\u001b[1;32m     27\u001b[0m     AutoTokenizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     TrainingArguments,\n\u001b[1;32m     34\u001b[0m )\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'SchemaInferenceError' from 'datasets.arrow_writer' (/opt/conda/lib/python3.10/site-packages/datasets/arrow_writer.py)"
     ]
    }
   ],
   "source": [
    "!pip install numpy matplotlib -q\n",
    "! pip install -q transformers[torch] einops accelerate bitsandbytes peft trl\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T05:27:36.396459Z",
     "iopub.status.busy": "2024-01-22T05:27:36.395536Z",
     "iopub.status.idle": "2024-01-22T05:27:36.430972Z",
     "shell.execute_reply": "2024-01-22T05:27:36.429931Z",
     "shell.execute_reply.started": "2024-01-22T05:27:36.396427Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from transformers import AutoTokenizer,AutoModelForCausalLM\n",
    "from transformers import pipeline\n",
    "import re\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T05:27:39.826436Z",
     "iopub.status.busy": "2024-01-22T05:27:39.825986Z",
     "iopub.status.idle": "2024-01-22T05:27:39.855729Z",
     "shell.execute_reply": "2024-01-22T05:27:39.854418Z",
     "shell.execute_reply.started": "2024-01-22T05:27:39.826401Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfe7ccabdc534d5ca239ae06ad38260d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T05:27:50.500302Z",
     "iopub.status.busy": "2024-01-22T05:27:50.499813Z",
     "iopub.status.idle": "2024-01-22T05:27:50.523073Z",
     "shell.execute_reply": "2024-01-22T05:27:50.521956Z",
     "shell.execute_reply.started": "2024-01-22T05:27:50.500246Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/kaggle/input/finetune/3.txt',\n",
       " '/kaggle/input/finetune/10.txt',\n",
       " '/kaggle/input/finetune/19.txt',\n",
       " '/kaggle/input/finetune/5.txt',\n",
       " '/kaggle/input/finetune/7.txt',\n",
       " '/kaggle/input/finetune/8.txt',\n",
       " '/kaggle/input/finetune/18.txt',\n",
       " '/kaggle/input/finetune/17.txt',\n",
       " '/kaggle/input/finetune/11.txt',\n",
       " '/kaggle/input/finetune/0.txt',\n",
       " '/kaggle/input/finetune/9.txt',\n",
       " '/kaggle/input/finetune/16.txt',\n",
       " '/kaggle/input/finetune/1.txt',\n",
       " '/kaggle/input/finetune/13.txt',\n",
       " '/kaggle/input/finetune/14.txt',\n",
       " '/kaggle/input/finetune/12.txt',\n",
       " '/kaggle/input/finetune/15.txt',\n",
       " '/kaggle/input/finetune/2.txt',\n",
       " '/kaggle/input/finetune/4.txt',\n",
       " '/kaggle/input/finetune/6.txt']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "\n",
    "files=[]\n",
    "\n",
    "for fi in glob.glob(\"/kaggle/input/finetune/*.txt\"):\n",
    "    files.append(fi)\n",
    "\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T05:28:02.922487Z",
     "iopub.status.busy": "2024-01-22T05:28:02.922036Z",
     "iopub.status.idle": "2024-01-22T05:28:03.501157Z",
     "shell.execute_reply": "2024-01-22T05:28:03.500168Z",
     "shell.execute_reply.started": "2024-01-22T05:28:02.922454Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "389ab7c8430740b28103a194dee7f41d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset text/default to /root/.cache/huggingface/datasets/text/default-46ee42a2ecad3455/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7307e7c2f7d449cb2c91a013274945f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c249cbb2284d42b5b0c6a60119f24d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Extracting data files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset text downloaded and prepared to /root/.cache/huggingface/datasets/text/default-46ee42a2ecad3455/0.0.0/4b86d314f7236db91f0a0f5cda32d4375445e64c5eda2692655dd99c2dac68e8. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12860943d57340b2bbc8c3e2c990cb70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"text\", data_files=files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T05:28:52.268569Z",
     "iopub.status.busy": "2024-01-22T05:28:52.268135Z",
     "iopub.status.idle": "2024-01-22T05:28:53.169295Z",
     "shell.execute_reply": "2024-01-22T05:28:53.168389Z",
     "shell.execute_reply.started": "2024-01-22T05:28:52.268537Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61721aaa45394b7cb6c46de607f69837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7605ca0ae802487a94f8e39ae2a4b471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d3f0230e95e4966b05bbef5e88ad26b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c52d3d23fffa4e91863013a7b56f9da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model=\"meta-llama/Llama-2-7b-hf\"\n",
    "tokenizer=AutoTokenizer.from_pretrained(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T05:31:04.080698Z",
     "iopub.status.busy": "2024-01-22T05:31:04.080293Z",
     "iopub.status.idle": "2024-01-22T05:31:04.086010Z",
     "shell.execute_reply": "2024-01-22T05:31:04.084956Z",
     "shell.execute_reply.started": "2024-01-22T05:31:04.080661Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T05:31:06.362234Z",
     "iopub.status.busy": "2024-01-22T05:31:06.361832Z",
     "iopub.status.idle": "2024-01-22T05:31:15.540383Z",
     "shell.execute_reply": "2024-01-22T05:31:15.539382Z",
     "shell.execute_reply.started": "2024-01-22T05:31:06.362202Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    "
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "882117b805a349779bb0d3787105c4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#0:   0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94e9a1481b0b467e8df1da38bf3d7fe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "#1:   0%|          | 0/15 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed76bee954964e1196ccc3a15613eed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/29310 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], max_length=64, truncation=True, padding=\"max_length\")\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True, num_proc=2, remove_columns=[\"text\"])\n",
    "    \n",
    "def copy_input_ids(example):\n",
    "    example[\"labels\"] = example[\"input_ids\"].copy()\n",
    "    return example\n",
    "\n",
    "tokenized_datasets = tokenized_datasets.map(copy_input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T05:31:15.542715Z",
     "iopub.status.busy": "2024-01-22T05:31:15.542380Z",
     "iopub.status.idle": "2024-01-22T05:31:15.548480Z",
     "shell.execute_reply": "2024-01-22T05:31:15.547371Z",
     "shell.execute_reply.started": "2024-01-22T05:31:15.542684Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T05:32:04.870708Z",
     "iopub.status.busy": "2024-01-22T05:32:04.869884Z",
     "iopub.status.idle": "2024-01-22T05:32:04.875631Z",
     "shell.execute_reply": "2024-01-22T05:32:04.874543Z",
     "shell.execute_reply.started": "2024-01-22T05:32:04.870673Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import BitsAndBytesConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T05:32:24.359500Z",
     "iopub.status.busy": "2024-01-22T05:32:24.359070Z",
     "iopub.status.idle": "2024-01-22T05:32:24.366604Z",
     "shell.execute_reply": "2024-01-22T05:32:24.365419Z",
     "shell.execute_reply.started": "2024-01-22T05:32:24.359469Z"
    }
   },
   "outputs": [],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T05:32:45.312825Z",
     "iopub.status.busy": "2024-01-22T05:32:45.312424Z",
     "iopub.status.idle": "2024-01-22T05:34:03.045205Z",
     "shell.execute_reply": "2024-01-22T05:34:03.044037Z",
     "shell.execute_reply.started": "2024-01-22T05:32:45.312780Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "deba3156bee8426da2fbbd3c74c4055a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/609 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc46fba95ef7414fa4e570cc646ed001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a549af1df034266a91857f6d3189054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c451fb9e1cf42808f1a578749aa4cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41fad43ddf7d4b75a5997a7071c700db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "097d7d9d51b74efa82b5f24573eacc72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c706063af0b41ebb6d61830a60af407",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "original_model = AutoModelForCausalLM.from_pretrained(\n",
    "        model,\n",
    "        quantization_config=bnb_config,\n",
    "        device_map=\"auto\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T05:34:03.047509Z",
     "iopub.status.busy": "2024-01-22T05:34:03.047133Z",
     "iopub.status.idle": "2024-01-22T05:34:03.052986Z",
     "shell.execute_reply": "2024-01-22T05:34:03.051918Z",
     "shell.execute_reply.started": "2024-01-22T05:34:03.047479Z"
    }
   },
   "outputs": [],
   "source": [
    "from peft import LoraConfig, get_peft_model, TaskType\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=8, # Rank\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.1,\n",
    "\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T05:34:03.054747Z",
     "iopub.status.busy": "2024-01-22T05:34:03.054407Z",
     "iopub.status.idle": "2024-01-22T05:34:06.788850Z",
     "shell.execute_reply": "2024-01-22T05:34:06.787716Z",
     "shell.execute_reply.started": "2024-01-22T05:34:03.054720Z"
    }
   },
   "outputs": [],
   "source": [
    "peft_model = get_peft_model(original_model,lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T05:35:31.743256Z",
     "iopub.status.busy": "2024-01-22T05:35:31.742408Z",
     "iopub.status.idle": "2024-01-22T05:35:31.747992Z",
     "shell.execute_reply": "2024-01-22T05:35:31.746831Z",
     "shell.execute_reply.started": "2024-01-22T05:35:31.743221Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T05:44:30.075165Z",
     "iopub.status.busy": "2024-01-22T05:44:30.074792Z",
     "iopub.status.idle": "2024-01-22T05:44:30.086199Z",
     "shell.execute_reply": "2024-01-22T05:44:30.085101Z",
     "shell.execute_reply.started": "2024-01-22T05:44:30.075134Z"
    }
   },
   "outputs": [],
   "source": [
    "peft_training_args = TrainingArguments(\n",
    "    output_dir=\"llama-2-7b-test1\",\n",
    "    learning_rate=1e-3,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.001,\n",
    "    per_device_train_batch_size=4,\n",
    "    save_strategy=\"steps\",\n",
    "    #evaluation_strategy=\"steps\",\n",
    "    save_steps=500,\n",
    "    save_total_limit=2,\n",
    "    #load_best_model_at_end=True,\n",
    "    fp16=True,\n",
    "    report_to='none'\n",
    ")\n",
    "\n",
    "peft_trainer = Trainer(\n",
    "    model=peft_model,\n",
    "    args=peft_training_args,\n",
    "    train_dataset=tokenized_datasets['train'],\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-22T05:44:30.473620Z",
     "iopub.status.busy": "2024-01-22T05:44:30.472795Z",
     "iopub.status.idle": "2024-01-22T08:57:19.644571Z",
     "shell.execute_reply": "2024-01-22T08:57:19.643597Z",
     "shell.execute_reply.started": "2024-01-22T05:44:30.473587Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='7328' max='7328' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [7328/7328 3:12:47, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.343000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.356100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.316500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.285800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.263000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.236200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.226300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.195200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.172500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>1.163800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>1.159500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>1.147600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>1.118200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7000</td>\n",
       "      <td>1.107100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=7328, training_loss=1.2153736264424553, metrics={'train_runtime': 11568.6312, 'train_samples_per_second': 2.534, 'train_steps_per_second': 0.633, 'total_flos': 7.44131237511168e+16, 'train_loss': 1.2153736264424553, 'epoch': 1.0})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4189467,
     "sourceId": 7234726,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
