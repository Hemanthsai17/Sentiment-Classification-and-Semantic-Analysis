{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-11T10:55:35.478668Z",
     "iopub.status.busy": "2024-03-11T10:55:35.478089Z",
     "iopub.status.idle": "2024-03-11T10:55:42.375646Z",
     "shell.execute_reply": "2024-03-11T10:55:42.374675Z",
     "shell.execute_reply.started": "2024-03-11T10:55:35.478638Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, AutoTokenizer\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-11T10:56:02.820202Z",
     "iopub.status.busy": "2024-03-11T10:56:02.819842Z",
     "iopub.status.idle": "2024-03-11T11:17:13.942906Z",
     "shell.execute_reply": "2024-03-11T11:17:13.941887Z",
     "shell.execute_reply.started": "2024-03-11T10:56:02.820174Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1af11370b92406cae8e7673bc0f76a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/394 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "495fa2995d094ec78ee95e14ad9ff4b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/472k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e6207ffb8b1410e856a5348eac7d72d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69632bbf2b144e14a7e8114bc2bfd759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/951k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cd3a49ac18f4fbcb333fbbda12b1c57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/870 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4789c32030d4671b1ca32529f8c87a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sampathlonka/San-BERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0009699321047526673\n",
      "Precision: 0.0\n",
      "Recall: 0.0\n",
      "F1-Score: 0.0\n",
      "Classification Report:\n",
      "                                                                                                            precision    recall  f1-score   support\n",
      "\n",
      "                                                                                           glani - guilty       0.00      0.00      0.00         3\n",
      "                                                                             sanka - doubt (apprehension)       0.00      0.00      0.00        20\n",
      "                                                                            asuya/irsya - jealousy (envy)       0.00      0.00      0.00        10\n",
      "                                                                                          srama - fatigue       0.00      0.00      0.00        10\n",
      "capalya/capalatha/capala - impudence [rude behavior that does not show respect for others] (unsteadiness)       0.00      0.00      0.00        12\n",
      "                                                                      harsa - jubiliation,enjoyment (joy)       0.00      0.00      0.00       128\n",
      "                                                               avega - intense emotion (agitation/flurry)       0.00      0.00      0.00        99\n",
      "                                                                autsukya - eagerness (impatience/longing)       0.00      0.00      0.00        40\n",
      "                                                        avahittha - concealment (hiding of true feelings)       0.00      0.00      0.00        12\n",
      "                                                                    unmada - craziness (insanity/madness)       0.00      0.00      0.00         2\n",
      "                                                                                     mriti/marana - death       0.00      0.00      0.00        38\n",
      "                                                                                               no emotion       0.00      0.00      0.00       140\n",
      "                                                                                                Shringara       0.00      0.00      0.00        59\n",
      "                                                                                                   Karuna       0.00      0.00      0.00        97\n",
      "                                                                                                   Raudra       0.00      0.00      0.00       114\n",
      "                                                                                                    Veera       0.00      0.00      0.00       309\n",
      "                                                                                                Bhayanaka       0.00      0.00      0.00        68\n",
      "                                                                                                  Adbutha       0.00      0.00      0.00       225\n",
      "                                                                                                  Shantha       0.00      0.00      0.00       172\n",
      "                                                                                                Proudness       0.00      0.00      0.00        19\n",
      "                                                                                            Contemplation       0.00      0.00      0.00        10\n",
      "\n",
      "                                                                                                micro avg       0.00      0.00      0.00      1587\n",
      "                                                                                                macro avg       0.00      0.00      0.00      1587\n",
      "                                                                                             weighted avg       0.00      0.00      0.00      1587\n",
      "                                                                                              samples avg       0.00      0.00      0.00      1587\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in samples with no true labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Define a custom dataset class\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        encoding = self.tokenizer(text, truncation=True, padding='max_length', max_length=self.max_length, return_tensors='pt')\n",
    "        \n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].flatten(),\n",
    "            'attention_mask': encoding['attention_mask'].flatten(),\n",
    "            'labels': torch.tensor(label, dtype=torch.float)\n",
    "        }\n",
    "\n",
    "# Load your data\n",
    "# Assuming you have a DataFrame called 'data' with columns: 'text', 'Class A', 'Class B', 'Class C', ...\n",
    "data = pd.read_excel('/kaggle/input/decemtrail/modified_data.xlsx')\n",
    "\n",
    "# Define the model and tokenizer\n",
    "model_name = 'sampathlonka/San-BERT'\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertForSequenceClassification.from_pretrained(model_name, num_labels=len(data.columns) - 1)\n",
    "\n",
    "# Split the data into texts and labels\n",
    "texts = data['Text'].tolist()\n",
    "labels = data.iloc[:, 1:].values.tolist()\n",
    "\n",
    "# Define dataset and dataloader\n",
    "dataset = CustomDataset(texts, labels, tokenizer, max_length=128)\n",
    "dataloader = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "# Define optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=2e-5)\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "epochs = 3\n",
    "for epoch in range(epochs):\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch in dataloader:\n",
    "        input_ids = batch['input_ids']\n",
    "        attention_mask = batch['attention_mask']\n",
    "        labels = batch['labels']\n",
    "        \n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        predictions.extend(torch.sigmoid(logits).cpu().numpy())\n",
    "        true_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "threshold = 0.5\n",
    "binary_predictions = [[1 if p >= threshold else 0 for p in pred] for pred in predictions]\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(true_labels, binary_predictions)\n",
    "precision = precision_score(true_labels, binary_predictions, average='micro')\n",
    "recall = recall_score(true_labels, binary_predictions, average='micro')\n",
    "f1 = f1_score(true_labels, binary_predictions, average='micro')\n",
    "classification_rep = classification_report(true_labels, binary_predictions, target_names=data.columns[1:])\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n",
    "print(\"Classification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4577736,
     "sourceId": 7814608,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
