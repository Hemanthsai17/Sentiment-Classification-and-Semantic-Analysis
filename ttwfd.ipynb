{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T05:15:52.412597Z",
     "iopub.status.busy": "2024-01-30T05:15:52.412012Z",
     "iopub.status.idle": "2024-01-30T05:16:51.162364Z",
     "shell.execute_reply": "2024-01-30T05:16:51.161457Z",
     "shell.execute_reply.started": "2024-01-30T05:15:52.412563Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 23.3.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|████████████████████████████████████████████████████████████████████████████| 870/870 [00:00<?, ?B/s]\n",
      "pytorch_model.bin: 100%|████████████████████████████████████████████████████████████| 438M/438M [01:38<00:00, 4.45MB/s]\n",
      "generation_config.json: 100%|███████████████████████████████████████████████████████████████| 90.0/90.0 [00:00<?, ?B/s]\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers[torch] -q\n",
    "!pip install numpy matplotlib -q\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from transformers import AutoTokenizer,AutoModelForMaskedLM\n",
    "from transformers import pipeline\n",
    "import re\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "model = AutoModelForMaskedLM.from_pretrained('sampathlonka/San-BERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T05:16:51.164705Z",
     "iopub.status.busy": "2024-01-30T05:16:51.164123Z",
     "iopub.status.idle": "2024-01-30T05:16:51.173454Z",
     "shell.execute_reply": "2024-01-30T05:16:51.172550Z",
     "shell.execute_reply.started": "2024-01-30T05:16:51.164672Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForMaskedLM(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cls): BertOnlyMLMHead(\n",
       "    (predictions): BertLMPredictionHead(\n",
       "      (transform): BertPredictionHeadTransform(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (transform_act_fn): GELUActivation()\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      )\n",
       "      (decoder): Linear(in_features=768, out_features=30522, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T05:16:51.175131Z",
     "iopub.status.busy": "2024-01-30T05:16:51.174774Z",
     "iopub.status.idle": "2024-01-30T05:16:52.547993Z",
     "shell.execute_reply": "2024-01-30T05:16:52.547007Z",
     "shell.execute_reply.started": "2024-01-30T05:16:51.175099Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "from transformers import PreTrainedTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T05:16:52.551336Z",
     "iopub.status.busy": "2024-01-30T05:16:52.550555Z",
     "iopub.status.idle": "2024-01-30T05:16:53.815414Z",
     "shell.execute_reply": "2024-01-30T05:16:53.814397Z",
     "shell.execute_reply.started": "2024-01-30T05:16:52.551298Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "tokenizer_config.json: 100%|███████████████████████████████████████████████████████████| 394/394 [00:00<00:00, 395kB/s]\n",
      "vocab.txt: 100%|█████████████████████████████████████████████████████████████████████| 472k/472k [00:00<00:00, 707kB/s]\n",
      "tokenizer.json: 100%|███████████████████████████████████████████████████████████████| 951k/951k [00:00<00:00, 1.46MB/s]\n",
      "special_tokens_map.json: 100%|████████████████████████████████████████████████████████████████| 125/125 [00:00<?, ?B/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertTokenizerFast(name_or_path='sampathlonka/San-BERT', vocab_size=30522, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t0: AddedToken(\"[PAD]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t1: AddedToken(\"[UNK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t2: AddedToken(\"[CLS]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t3: AddedToken(\"[SEP]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t4: AddedToken(\"[MASK]\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer1=AutoTokenizer.from_pretrained('sampathlonka/San-BERT')\n",
    "tokenizer1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T05:16:53.817003Z",
     "iopub.status.busy": "2024-01-30T05:16:53.816691Z",
     "iopub.status.idle": "2024-01-30T05:16:53.825866Z",
     "shell.execute_reply": "2024-01-30T05:16:53.824936Z",
     "shell.execute_reply.started": "2024-01-30T05:16:53.816976Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 2050, 1877, 4120, 29572, 1918, 10867, 1029, 20602, 1812, 12720, 50, 3], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer1(\"अथ तस्य विवाहकौतुकम् ललितम् बिभ्रत एव पार्थिवः|\")\n",
    "#हस्तगामिनीमकरोदिन्दुमतीमिवापराम्"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T05:16:53.827773Z",
     "iopub.status.busy": "2024-01-30T05:16:53.826918Z",
     "iopub.status.idle": "2024-01-30T05:16:53.890625Z",
     "shell.execute_reply": "2024-01-30T05:16:53.889712Z",
     "shell.execute_reply.started": "2024-01-30T05:16:53.827745Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "folder_path = r\"D:\\github archive\\Abstractive\\Data\\unsupervised\\text_files\"  # Replace this with the path to your folder\n",
    "\n",
    "# Get the list of all files in the folder with full path\n",
    "files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if os.path.isfile(os.path.join(folder_path, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T05:16:53.892714Z",
     "iopub.status.busy": "2024-01-30T05:16:53.891883Z",
     "iopub.status.idle": "2024-01-30T05:17:26.894117Z",
     "shell.execute_reply": "2024-01-30T05:17:26.893063Z",
     "shell.execute_reply.started": "2024-01-30T05:16:53.892676Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data files: 100%|████████████████████████████████████████████████████████████████████| 1/1 [00:00<?, ?it/s]\n",
      "Extracting data files: 100%|█████████████████████████████████████████████████████████████| 1/1 [00:13<00:00, 13.65s/it]\n",
      "Generating train split: 1854091 examples [00:16, 103718.75 examples/s]"
     ]
    }
   ],
   "source": [
    "path=r\"D:\\github archive\\Abstractive\\Data\\unsupervised\\text_files\"\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"text\", data_files=files,split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T05:17:26.897249Z",
     "iopub.status.busy": "2024-01-30T05:17:26.896428Z",
     "iopub.status.idle": "2024-01-30T05:17:26.904341Z",
     "shell.execute_reply": "2024-01-30T05:17:26.903419Z",
     "shell.execute_reply.started": "2024-01-30T05:17:26.897210Z"
    }
   },
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T05:17:26.906036Z",
     "iopub.status.busy": "2024-01-30T05:17:26.905678Z",
     "iopub.status.idle": "2024-01-30T05:17:31.011026Z",
     "shell.execute_reply": "2024-01-30T05:17:31.010010Z",
     "shell.execute_reply.started": "2024-01-30T05:17:26.906003Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T05:17:31.015120Z",
     "iopub.status.busy": "2024-01-30T05:17:31.014109Z",
     "iopub.status.idle": "2024-01-30T05:17:56.095853Z",
     "shell.execute_reply": "2024-01-30T05:17:56.094902Z",
     "shell.execute_reply.started": "2024-01-30T05:17:31.015088Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset['text'][2596]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T05:19:18.317290Z",
     "iopub.status.busy": "2024-01-30T05:19:18.316130Z",
     "iopub.status.idle": "2024-01-30T05:19:18.322587Z",
     "shell.execute_reply": "2024-01-30T05:19:18.321583Z",
     "shell.execute_reply.started": "2024-01-30T05:19:18.317252Z"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def get_training_corpus():\n",
    "    for start_idx in tqdm(range(0, len(dataset)), desc=\"Processing dataset\"):\n",
    "        samples = dataset[start_idx]\n",
    "        yield samples[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T05:19:20.205176Z",
     "iopub.status.busy": "2024-01-30T05:19:20.204542Z",
     "iopub.status.idle": "2024-01-30T05:19:20.209602Z",
     "shell.execute_reply": "2024-01-30T05:19:20.208308Z",
     "shell.execute_reply.started": "2024-01-30T05:19:20.205130Z"
    }
   },
   "outputs": [],
   "source": [
    "training_corpus = get_training_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-30T05:19:57.229079Z",
     "iopub.status.busy": "2024-01-30T05:19:57.228695Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tokenizing:   0%|          | 0/11832638 [00:00<?, ?it/s]\n",
      "Tokenizing:   0%|          | 1038/11832638 [00:00<19:00, 10376.67it/s]\n",
      "Tokenizing:   0%|          | 2691/11832638 [00:00<14:05, 13992.80it/s].02it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 4273/11832638 [00:00<13:17, 14826.15it/s].19it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 5756/11832638 [00:00<14:48, 13317.49it/s].95it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 7109/11832638 [00:00<15:49, 12448.55it/s].02it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 8372/11832638 [00:00<16:32, 11909.52it/s].44it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 9576/11832638 [00:00<16:42, 11792.66it/s].57it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 10763/11832638 [00:00<17:26, 11301.77it/s].12it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 11900/11832638 [00:00<17:40, 11151.04it/s].24it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 13019/11832638 [00:01<17:38, 11161.49it/s].38it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 14138/11832638 [00:01<17:52, 11014.63it/s].49it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 15241/11832638 [00:01<18:52, 10432.76it/s].87it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 16290/11832638 [00:01<19:31, 10087.39it/s].11it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 17303/11832638 [00:01<20:10, 9763.30it/s] 84it/s] \u001b[A\n",
      "Tokenizing:   0%|          | 18432/11832638 [00:01<19:34, 10060.44it/s]35it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 19529/11832638 [00:01<19:05, 10316.79it/s].70it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 20644/11832638 [00:01<18:39, 10554.87it/s].58it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 21905/11832638 [00:01<17:39, 11152.38it/s].02it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 23025/11832638 [00:02<20:27, 9618.80it/s] .46it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 24026/11832638 [00:02<29:38, 6638.31it/s].24it/s] \u001b[A\n",
      "Tokenizing:   0%|          | 24836/11832638 [00:02<35:04, 5611.25it/s].59it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 25516/11832638 [00:02<36:04, 5453.98it/s].49it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 26141/11832638 [00:02<38:38, 5092.27it/s].84it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 26880/11832638 [00:03<37:16, 5278.20it/s].82it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 27449/11832638 [00:03<37:04, 5305.74it/s].77it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 28009/11832638 [00:03<36:41, 5362.44it/s].27it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 28568/11832638 [00:03<36:40, 5364.22it/s].24it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 29120/11832638 [00:03<37:06, 5302.13it/s].73it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 29678/11832638 [00:03<36:35, 5376.63it/s].50it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 30224/11832638 [00:03<38:17, 5136.47it/s].26it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 31488/11832638 [00:03<36:52, 5333.75it/s].49it/s]\u001b[A\n",
      "Processing dataset:   0%|          | 31488/11832638 [00:03<37:07, 5297.91it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 32029/11832638 [00:03<40:07, 4901.73it/s].60it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 32534/11832638 [00:04<39:57, 4922.22it/s].57it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 33575/11832638 [00:04<39:58, 4919.44it/s].48it/s]\u001b[A\n",
      "Processing dataset:   0%|          | 33577/11832638 [00:04<40:17, 4881.45it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 34816/11832638 [00:04<43:11, 4552.38it/s].77it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 35407/11832638 [00:04<40:13, 4888.49it/s].67it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 36050/11832638 [00:04<37:09, 5290.91it/s].72it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 36933/11832638 [00:04<31:26, 6252.07it/s].57it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 38044/11832638 [00:05<25:49, 7610.35it/s].00it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 39079/11832638 [00:05<23:25, 8391.79it/s].54it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 40204/11832638 [00:05<21:19, 9219.46it/s].81it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 41151/11832638 [00:05<21:08, 9292.58it/s].51it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 42097/11832638 [00:05<22:08, 8878.29it/s].31it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 43008/11832638 [00:05<22:39, 8670.58it/s].92it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 44032/11832638 [00:05<22:06, 8886.34it/s].38it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 44929/11832638 [00:05<22:15, 8826.23it/s].68it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 45817/11832638 [00:05<22:16, 8816.12it/s].42it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 46807/11832638 [00:05<21:31, 9128.12it/s].37it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 47802/11832638 [00:06<20:57, 9367.93it/s].14it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 48884/11832638 [00:06<20:02, 9795.33it/s].71it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 49867/11832638 [00:06<20:06, 9762.54it/s].56it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 50944/11832638 [00:06<19:54, 9865.47it/s].61it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 52104/11832638 [00:06<18:55, 10373.50it/s]99it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 53346/11832638 [00:06<17:53, 10977.63it/s].04it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 54721/11832638 [00:06<16:38, 11799.61it/s].52it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 55904/11832638 [00:06<16:42, 11746.95it/s].27it/s]\u001b[A\n",
      "Processing dataset:   0%|          | 55906/11832638 [00:06<16:45, 11712.70it/s]\u001b[A\n",
      "Tokenizing:   0%|          | 58224/11832638 [00:06<17:28, 11225.70it/s].48it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 59350/11832638 [00:07<17:34, 11166.03it/s].37it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 60469/11832638 [00:07<18:14, 10757.38it/s].73it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 61549/11832638 [00:07<18:48, 10434.17it/s].78it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 62596/11832638 [00:07<19:09, 10243.71it/s].85it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 63703/11832638 [00:07<18:43, 10478.18it/s].66it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 64754/11832638 [00:07<19:16, 10179.58it/s].04it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 65775/11832638 [00:07<19:19, 10150.46it/s].46it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 66816/11832638 [00:07<19:22, 10119.03it/s].24it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 67840/11832638 [00:07<19:31, 10042.39it/s].36it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 68879/11832638 [00:08<19:19, 10142.01it/s].16it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 69895/11832638 [00:08<19:30, 10048.88it/s].25it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 70901/11832638 [00:08<19:47, 9906.60it/s] .02it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 71936/11832638 [00:08<19:41, 9953.02it/s].42it/s] \u001b[A\n",
      "Tokenizing:   1%|          | 72960/11832638 [00:08<19:44, 9927.17it/s].17it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 73984/11832638 [00:08<19:42, 9947.80it/s].70it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 75008/11832638 [00:08<19:43, 9936.59it/s].91it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 76025/11832638 [00:08<19:35, 10003.17it/s]34it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 77056/11832638 [00:08<19:40, 9955.64it/s] 77it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 78055/11832638 [00:08<19:40, 9961.33it/s].45it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 79085/11832638 [00:09<19:28, 10060.56it/s]45it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 80128/11832638 [00:09<19:25, 10085.61it/s].27it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 81152/11832638 [00:09<19:21, 10113.68it/s].05it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 82165/11832638 [00:09<19:21, 10116.76it/s].03it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 83177/11832638 [00:09<19:29, 10049.00it/s].84it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 84210/11832638 [00:09<19:19, 10130.27it/s].98it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 85229/11832638 [00:09<19:17, 10146.36it/s].97it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 86272/11832638 [00:09<19:24, 10089.70it/s].21it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 87314/11832638 [00:09<19:13, 10184.21it/s].57it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 88333/11832638 [00:09<19:14, 10176.67it/s].40it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 89351/11832638 [00:10<20:06, 9732.97it/s] .52it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 90329/11832638 [00:10<20:05, 9739.55it/s].46it/s] \u001b[A\n",
      "Tokenizing:   1%|          | 91306/11832638 [00:10<20:08, 9713.81it/s].07it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 92356/11832638 [00:10<19:40, 9943.27it/s].26it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 93450/11832638 [00:10<19:06, 10236.41it/s]81it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 94476/11832638 [00:10<19:10, 10198.92it/s].56it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 95533/11832638 [00:10<18:58, 10306.97it/s].79it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 96606/11832638 [00:10<18:44, 10432.22it/s].70it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 97650/11832638 [00:10<19:19, 10121.38it/s].77it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 98686/11832638 [00:11<19:11, 10190.03it/s].57it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 99708/11832638 [00:11<19:10, 10197.19it/s].68it/s]\u001b[A\n",
      "Processing dataset:   1%|          | 99708/11832638 [00:11<19:11, 10191.23it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 101888/11832638 [00:11<18:42, 10450.91it/s].76it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 102961/11832638 [00:11<18:33, 10531.22it/s].26it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 104036/11832638 [00:11<18:27, 10594.09it/s].05it/s]\u001b[A\n",
      "Processing dataset:   1%|          | 104036/11832638 [00:11<18:28, 10576.20it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 106133/11832638 [00:11<19:17, 10134.19it/s].14it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 107149/11832638 [00:11<19:23, 10081.58it/s].30it/s]\u001b[A\n",
      "Processing dataset:   1%|          | 107151/11832638 [00:11<19:26, 10047.66it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 108159/11832638 [00:11<19:55, 9810.24it/s] 82it/s] \u001b[A\n",
      "Tokenizing:   1%|          | 110138/11832638 [00:12<20:16, 9638.32it/s].20it/s]\u001b[A\n",
      "Processing dataset:   1%|          | 110142/11832638 [00:12<20:25, 9565.70it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 111104/11832638 [00:12<21:37, 9037.06it/s].74it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 112174/11832638 [00:12<20:33, 9500.73it/s].97it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 113376/11832638 [00:12<19:07, 10217.24it/s].58it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 114434/11832638 [00:12<18:55, 10321.80it/s].28it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 115507/11832638 [00:12<18:42, 10440.67it/s].83it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 116682/11832638 [00:12<18:02, 10823.85it/s].36it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 117786/11832638 [00:12<17:56, 10886.65it/s].17it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 120064/11832638 [00:13<17:34, 11107.07it/s].39it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 121177/11832638 [00:13<17:37, 11073.84it/s].91it/s]\u001b[A\n",
      "Processing dataset:   1%|          | 121177/11832638 [00:13<17:45, 10986.70it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 122286/11832638 [00:13<18:07, 10769.85it/s].19it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 123382/11832638 [00:13<18:01, 10825.38it/s].07it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 124467/11832638 [00:13<18:06, 10774.81it/s].79it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 125648/11832638 [00:13<17:38, 11055.66it/s].87it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 126761/11832638 [00:13<17:37, 11073.76it/s].11it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 127875/11832638 [00:13<17:35, 11090.24it/s].68it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 130072/11832638 [00:14<18:13, 10705.27it/s].07it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 131201/11832638 [00:14<17:56, 10874.78it/s].59it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 132356/11832638 [00:14<17:36, 11072.26it/s].90it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 133564/11832638 [00:14<17:08, 11370.72it/s].48it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 134703/11832638 [00:14<17:09, 11365.55it/s].44it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 135909/11832638 [00:14<16:50, 11570.32it/s].50it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 137067/11832638 [00:14<16:52, 11553.85it/s].92it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 138240/11832638 [00:14<16:59, 11471.34it/s].31it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 139396/11832638 [00:14<16:57, 11494.91it/s].77it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 140546/11832638 [00:14<17:37, 11058.43it/s].10it/s]\u001b[A\n",
      "Processing dataset:   1%|          | 140546/11832638 [00:14<17:37, 11052.34it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 142735/11832638 [00:15<18:13, 10688.16it/s].21it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 143843/11832638 [00:15<18:02, 10801.23it/s].76it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 144926/11832638 [00:15<18:39, 10435.68it/s].32it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 145973/11832638 [00:15<18:42, 10410.75it/s].61it/s]\u001b[A\n",
      "Tokenizing:   1%|          | 147200/11832638 [00:15<17:58, 10837.33it/s].04it/s]\u001b[A\n",
      "Tokenizing:   1%|▏         | 148480/11832638 [00:15<17:16, 11267.55it/s].43it/s]\u001b[A\n",
      "Tokenizing:   1%|▏         | 149791/11832638 [00:15<16:29, 11803.39it/s].88it/s]\u001b[A\n",
      "Tokenizing:   1%|▏         | 150974/11832638 [00:15<17:13, 11298.38it/s].29it/s]\u001b[A\n",
      "Tokenizing:   1%|▏         | 152110/11832638 [00:15<17:21, 11220.17it/s].01it/s]\u001b[A\n",
      "Tokenizing:   1%|▏         | 153344/11832638 [00:16<16:57, 11473.38it/s].94it/s]\u001b[A\n",
      "Tokenizing:   1%|▏         | 154761/11832638 [00:16<15:52, 12255.80it/s].93it/s]\u001b[A\n",
      "Tokenizing:   1%|▏         | 155992/11832638 [00:16<16:18, 11939.08it/s].98it/s]\u001b[A\n",
      "Tokenizing:   1%|▏         | 157191/11832638 [00:16<16:54, 11511.73it/s].16it/s]\u001b[A\n",
      "Tokenizing:   1%|▏         | 158348/11832638 [00:16<18:06, 10742.77it/s].67it/s]\u001b[A\n",
      "Tokenizing:   1%|▏         | 159434/11832638 [00:16<19:16, 10091.96it/s].14it/s]\u001b[A\n",
      "Tokenizing:   1%|▏         | 160456/11832638 [00:16<20:18, 9578.71it/s] .88it/s]\u001b[A\n",
      "Tokenizing:   1%|▏         | 161424/11832638 [00:16<20:40, 9406.37it/s].62it/s] \u001b[A\n",
      "Tokenizing:   1%|▏         | 162371/11832638 [00:16<20:50, 9332.15it/s].25it/s]\u001b[A\n",
      "Tokenizing:   1%|▏         | 163328/11832638 [00:17<21:02, 9244.93it/s].75it/s]\u001b[A\n",
      "Tokenizing:   1%|▏         | 164352/11832638 [00:17<20:39, 9413.29it/s].54it/s]\u001b[A\n",
      "Tokenizing:   1%|▏         | 165359/11832638 [00:17<20:15, 9598.33it/s].57it/s]\u001b[A\n",
      "Tokenizing:   1%|▏         | 166322/11832638 [00:17<21:03, 9230.42it/s].88it/s]\u001b[A\n",
      "Tokenizing:   1%|▏         | 167306/11832638 [00:17<20:40, 9401.35it/s].52it/s]\u001b[A\n",
      "Tokenizing:   1%|▏         | 168254/11832638 [00:17<20:37, 9423.43it/s].82it/s]\u001b[A\n",
      "Tokenizing:   1%|▏         | 169216/11832638 [00:17<20:42, 9385.17it/s].08it/s]\u001b[A\n",
      "Tokenizing:   1%|▏         | 170363/11832638 [00:17<19:27, 9991.51it/s].66it/s]\u001b[A\n",
      "Tokenizing:   1%|▏         | 171520/11832638 [00:17<18:43, 10382.74it/s].44it/s]\u001b[A\n",
      "Tokenizing:   1%|▏         | 172561/11832638 [00:18<18:47, 10340.10it/s].99it/s]\u001b[A\n",
      "Tokenizing:   1%|▏         | 173597/11832638 [00:18<19:22, 10032.64it/s].53it/s]\u001b[A\n",
      "Tokenizing:   1%|▏         | 174603/11832638 [00:18<19:29, 9964.58it/s] .05it/s]\u001b[A\n",
      "Tokenizing:   1%|▏         | 175770/11832638 [00:18<18:34, 10460.27it/s]93it/s] \u001b[A\n",
      "Tokenizing:   1%|▏         | 176896/11832638 [00:18<18:17, 10619.62it/s].49it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 177960/11832638 [00:18<18:32, 10477.97it/s].29it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 179089/11832638 [00:18<18:07, 10715.29it/s].41it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 180224/11832638 [00:18<18:04, 10745.88it/s].03it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 181405/11832638 [00:18<17:33, 11057.49it/s].02it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 182520/11832638 [00:18<17:31, 11083.62it/s].33it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 183630/11832638 [00:19<17:30, 11087.74it/s].42it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 184832/11832638 [00:19<17:24, 11154.46it/s].00it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 186074/11832638 [00:19<16:50, 11526.80it/s].57it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 187249/11832638 [00:19<16:44, 11591.06it/s].32it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 188416/11832638 [00:19<16:56, 11452.77it/s].99it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 189571/11832638 [00:19<16:54, 11480.41it/s].45it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 190735/11832638 [00:19<16:50, 11526.05it/s].24it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 191907/11832638 [00:19<16:45, 11582.44it/s].09it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 193066/11832638 [00:19<17:16, 11227.02it/s].32it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 194192/11832638 [00:19<18:20, 10573.56it/s].15it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 195258/11832638 [00:20<18:29, 10486.95it/s].75it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 196349/11832638 [00:20<18:17, 10605.26it/s].17it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 197415/11832638 [00:20<18:33, 10449.78it/s].93it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 198510/11832638 [00:20<18:18, 10593.70it/s].14it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 199573/11832638 [00:20<18:19, 10582.99it/s].30it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 200634/11832638 [00:20<18:30, 10476.49it/s].11it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 201726/11832638 [00:20<18:16, 10605.19it/s].82it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 202788/11832638 [00:20<18:26, 10513.17it/s].83it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 203841/11832638 [00:20<18:48, 10308.13it/s].84it/s]\u001b[A\n",
      "Processing dataset:   2%|▏         | 203841/11832638 [00:20<18:48, 10303.51it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 205886/11832638 [00:21<19:12, 10085.23it/s].20it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 206977/11832638 [00:21<18:46, 10323.80it/s].70it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 208067/11832638 [00:21<18:27, 10493.03it/s].26it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 209176/11832638 [00:21<18:09, 10668.94it/s].42it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 210432/11832638 [00:21<17:30, 11062.33it/s].43it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 211731/11832638 [00:21<16:39, 11628.43it/s].22it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 212912/11832638 [00:21<16:34, 11682.02it/s].99it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 214135/11832638 [00:21<16:21, 11843.03it/s].99it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 215320/11832638 [00:21<17:09, 11288.88it/s].58it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 216455/11832638 [00:22<17:11, 11265.55it/s].87it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 217586/11832638 [00:22<17:26, 11101.31it/s].45it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 218699/11832638 [00:22<18:49, 10285.09it/s].43it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 219740/11832638 [00:22<19:00, 10183.87it/s].84it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 220848/11832638 [00:22<18:32, 10433.73it/s].75it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 221952/11832638 [00:22<18:29, 10461.82it/s].69it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 223004/11832638 [00:22<18:34, 10414.64it/s].69it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 224049/11832638 [00:22<18:40, 10359.85it/s].63it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 225162/11832638 [00:22<18:16, 10584.07it/s].71it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 226228/11832638 [00:22<18:14, 10605.41it/s].71it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 227328/11832638 [00:23<18:20, 10549.32it/s].66it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 228397/11832638 [00:23<18:15, 10588.32it/s].84it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 229458/11832638 [00:23<18:15, 10592.75it/s].90it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 230559/11832638 [00:23<18:02, 10714.42it/s].98it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 231632/11832638 [00:23<18:36, 10394.15it/s].20it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 232674/11832638 [00:23<18:55, 10211.25it/s].02it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 233698/11832638 [00:23<19:23, 9968.53it/s] .43it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 234741/11832638 [00:23<19:08, 10098.61it/s]57it/s] \u001b[A\n",
      "Tokenizing:   2%|▏         | 235753/11832638 [00:23<19:31, 9895.15it/s] .41it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 236745/11832638 [00:24<19:55, 9696.49it/s].88it/s] \u001b[A\n",
      "Tokenizing:   2%|▏         | 237824/11832638 [00:24<19:29, 9916.55it/s].62it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 238869/11832638 [00:24<19:11, 10068.79it/s]65it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 239921/11832638 [00:24<18:56, 10199.28it/s].24it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 241020/11832638 [00:24<18:31, 10430.91it/s].75it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 242113/11832638 [00:24<18:15, 10578.32it/s].48it/s]\u001b[A\n",
      "Processing dataset:   2%|▏         | 242114/11832638 [00:24<18:17, 10557.46it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 244206/11832638 [00:24<19:12, 10053.36it/s].29it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 245214/11832638 [00:24<19:32, 9884.27it/s] .92it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 246205/11832638 [00:24<19:45, 9772.06it/s].72it/s] \u001b[A\n",
      "Tokenizing:   2%|▏         | 247184/11832638 [00:25<19:51, 9719.55it/s].41it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 248157/11832638 [00:25<19:52, 9712.33it/s].53it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 249129/11832638 [00:25<20:02, 9628.87it/s].20it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 250112/11832638 [00:25<20:09, 9575.18it/s].02it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 251136/11832638 [00:25<19:47, 9756.23it/s].49it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 252219/11832638 [00:25<19:09, 10072.62it/s]42it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 253228/11832638 [00:25<19:23, 9948.37it/s] .11it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 254224/11832638 [00:25<19:45, 9765.17it/s].23it/s] \u001b[A\n",
      "Tokenizing:   2%|▏         | 255232/11832638 [00:25<19:50, 9725.25it/s].18it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 256209/11832638 [00:25<19:48, 9736.62it/s].46it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 257258/11832638 [00:26<19:22, 9958.06it/s].85it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 258304/11832638 [00:26<19:17, 9995.96it/s].41it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 259451/11832638 [00:26<18:29, 10428.83it/s]03it/s]\u001b[A\n",
      "Processing dataset:   2%|▏         | 259451/11832638 [00:26<18:29, 10428.06it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 261506/11832638 [00:26<19:14, 10019.87it/s].68it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 262511/11832638 [00:26<19:15, 10012.49it/s]80it/s] \u001b[A\n",
      "Tokenizing:   2%|▏         | 263514/11832638 [00:26<19:45, 9762.04it/s] 71it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 264493/11832638 [00:26<20:09, 9564.85it/s].45it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 265575/11832638 [00:26<19:25, 9926.15it/s].76it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 266572/11832638 [00:27<19:23, 9937.79it/s].50it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 267587/11832638 [00:27<19:16, 9998.90it/s].71it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 268674/11832638 [00:27<18:47, 10255.91it/s]12it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 269701/11832638 [00:27<18:58, 10158.23it/s].71it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 270718/11832638 [00:27<19:33, 9854.74it/s] .75it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 271706/11832638 [00:27<19:58, 9649.00it/s].03it/s] \u001b[A\n",
      "Tokenizing:   2%|▏         | 272673/11832638 [00:27<20:23, 9451.82it/s].32it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 273655/11832638 [00:27<20:09, 9555.50it/s].92it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 274629/11832638 [00:27<20:02, 9608.70it/s].01it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 275592/11832638 [00:27<20:17, 9491.71it/s].54it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 276543/11832638 [00:28<20:37, 9341.70it/s].51it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 277479/11832638 [00:28<20:37, 9340.94it/s].19it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 278414/11832638 [00:28<21:15, 9060.48it/s].11it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 279322/11832638 [00:28<21:33, 8933.59it/s].75it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 280236/11832638 [00:28<21:24, 8991.06it/s].87it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 281137/11832638 [00:28<21:51, 8804.53it/s].78it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 282070/11832638 [00:28<21:29, 8955.33it/s].65it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 282967/11832638 [00:28<21:34, 8919.51it/s].59it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 283860/11832638 [00:28<21:54, 8787.66it/s].33it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 284740/11832638 [00:29<22:18, 8626.24it/s].85it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 285604/11832638 [00:29<22:23, 8592.64it/s].70it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 286464/11832638 [00:29<23:06, 8326.12it/s].15it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 287299/11832638 [00:29<23:22, 8229.91it/s].42it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 288124/11832638 [00:29<24:19, 7907.45it/s].35it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 288918/11832638 [00:29<24:44, 7777.36it/s].76it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 289698/11832638 [00:29<25:13, 7624.37it/s].14it/s]\u001b[A\n",
      "Tokenizing:   2%|▏         | 290462/11832638 [00:29<26:05, 7374.24it/s].56it/s]\u001b[A\n",
      "Processing dataset:   2%|▏         | 290462/11832638 [00:29<26:06, 7369.15it/s]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Assuming get_training_corpus() is defined as mentioned in the previous response\n",
    "\n",
    "# Wrap your iterator with tqdm\n",
    "total_samples = len(dataset)\n",
    "training_corpus_with_progress = tqdm(get_training_corpus(), desc=\"Tokenizing\", total=total_samples)\n",
    "\n",
    "new_tokenizer = tokenizer1.train_new_from_iterator(training_corpus_with_progress, 52000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-28T07:05:43.819895Z",
     "iopub.status.busy": "2024-01-28T07:05:43.819452Z",
     "iopub.status.idle": "2024-01-28T07:05:44.741975Z",
     "shell.execute_reply": "2024-01-28T07:05:44.740748Z",
     "shell.execute_reply.started": "2024-01-28T07:05:43.819862Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mnew_tokenizer\u001b[49m\u001b[38;5;241m.\u001b[39mvocab_size\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "new_tokenizer"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [],
   "dockerImageVersionId": 30636,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
