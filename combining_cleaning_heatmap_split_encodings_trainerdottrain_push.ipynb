{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1f83f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of Excel files to concatenate\n",
    "excel_files = ['raghuvamsha_sarga_01.xlsx','raghuvamsha_sarga_02.xlsx','raghuvamsha_sarga_03.xlsx',\n",
    "               'raghuvamsha_sarga_04.xlsx','raghuvamsha_sarga_05.xlsx','raghuvamsha_sarga_06.xlsx',\n",
    "               'raghuvamsha_sarga_07.xlsx','raghuvamsha_sarga_08.xlsx','raghuvamsha_sarga_09.xlsx',\n",
    "               'raghuvamsha_sarga_10.xlsx','raghuvamsha_sarga_11.xlsx','raghuvamsha_sarga_12.xlsx']\n",
    "\n",
    "# Create an empty DataFrame to store the concatenated data\n",
    "combined_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each Excel file and concatenate its data to the combined_data DataFrame\n",
    "for file in excel_files:\n",
    "    # Read data from the Excel file\n",
    "    data = pd.read_excel(file)\n",
    "    \n",
    "    # Concatenate data to the combined_data DataFrame\n",
    "    combined_data = pd.concat([combined_data, data], ignore_index=True)\n",
    "\n",
    "# Write the combined data to a new Excel file\n",
    "combined_data.to_excel('combined_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3e88e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770038f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4083cd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data['Text'] = combined_data['Text'].apply(lambda text: re.sub(r'\\n', '', str(text)))\n",
    "combined_data['Text'] = combined_data['Text'].apply(lambda text: re.sub(r'|', '', str(text)))\n",
    "combined_data['Text'] = combined_data['Text'].apply(lambda text: re.sub(r'॥', '', str(text)))\n",
    "combined_data['Text'] = combined_data['Text'].apply(lambda text: re.sub(r'३', '', str(text)))\n",
    "combined_data['Text'] = combined_data['Text'].apply(lambda text: re.sub(r'१', '', str(text)))\n",
    "combined_data['Text'] = combined_data['Text'].apply(lambda text: re.sub(r'२', '', str(text)))\n",
    "combined_data['Text'] = combined_data['Text'].apply(lambda text: re.sub(r'४', '', str(text)))\n",
    "combined_data['Text'] = combined_data['Text'].apply(lambda text: re.sub(r'५', '', str(text)))\n",
    "combined_data['Text'] = combined_data['Text'].apply(lambda text: re.sub(r'६', '', str(text)))\n",
    "combined_data['Text'] = combined_data['Text'].apply(lambda text: re.sub(r'७', '', str(text)))\n",
    "combined_data['Text'] = combined_data['Text'].apply(lambda text: re.sub(r'९', '', str(text)))\n",
    "combined_data['Text'] = combined_data['Text'].apply(lambda text: re.sub(r'०', '', str(text)))\n",
    "combined_data['Text'] = combined_data['Text'].apply(lambda text: re.sub(r'८', '', str(text)))\n",
    "combined_data['Text'] = combined_data['Text'].apply(lambda text: re.sub(r'-', '', str(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacc1ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data['Text'] = combined_data['Text'].apply(lambda text: re.sub(r'\\t', '', str(text)))\n",
    "combined_data['Text'] = combined_data['Text'].apply(lambda text: re.sub(r' ', '', str(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b5a101",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data['Text'][1030]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fffadf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data.to_excel('manipulated_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2374956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel('manipulated_data.xlsx')\n",
    "\n",
    "# Initialize variables to store the row, column, and maximum size\n",
    "max_size = 0\n",
    "max_row = 0\n",
    "max_col = 0\n",
    "\n",
    "# Iterate over all cells in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    for col in df.columns:\n",
    "        cell_content = str(df.at[index, col])\n",
    "        cell_size = len(cell_content)\n",
    "        if cell_size > max_size:\n",
    "            max_size = cell_size\n",
    "            max_row = index\n",
    "            max_col = col\n",
    "\n",
    "# Print the row, column, and maximum size\n",
    "print(f\"The cell with the maximum size is at row {max_row+1}, column {max_col}, with a size of {max_size}.\")\n",
    "print(f\"The content of the cell is: {df.at[max_row, max_col]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d9096e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel('manipulated_data.xlsx')\n",
    "\n",
    "# Create an empty list to store the sentiments for each instance\n",
    "sentiments = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Get the classes where the value is 1\n",
    "    instance_classes = [col for col in df.columns[1:] if row[col] == 1]\n",
    "    \n",
    "    # Append the list of classes to the sentiments list\n",
    "    sentiments.append(instance_classes)\n",
    "\n",
    "# Add a new column 'sentiments' to the DataFrame with the lists of classes\n",
    "df['sentiments'] = sentiments\n",
    "\n",
    "# Print the DataFrame to verify the changes\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f210ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('sentimented_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cb1851",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel('sentimented_data.xlsx')\n",
    "\n",
    "# Find the cell with the maximum number of elements in the 'sentiments' column\n",
    "max_length = 0\n",
    "max_row_index = -1\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Get the length of the list in the 'sentiments' column\n",
    "    sentiment_length = len(row['sentiments'])\n",
    "    \n",
    "    # Update max_length and max_row_index if the current length is greater\n",
    "    if sentiment_length > max_length:\n",
    "        max_length = sentiment_length\n",
    "        max_row_index = index\n",
    "\n",
    "# Print the row index and the maximum number of elements\n",
    "print(f\"The row with the maximum number of elements in the 'sentiments' column is at index {max_row_index}, with {max_length} elements.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233df078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('sentimented_data.xlsx')\n",
    "\n",
    "# Create a new column for each instance to store one sentiment\n",
    "for i in range(len(df)):\n",
    "    # Get one sentiment from the list of sentiments for each instance\n",
    "    sentiment = df.at[i, 'sentiments'][0] if len(df.at[i, 'sentiments']) > 0 else None\n",
    "    \n",
    "    # Add the sentiment to a new column for each instance\n",
    "    df.at[i, 'sentiment'] = sentiment\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7f94fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install seaborn -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84272f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# To ignore all warnings (not recommended unless you're sure about the consequences)\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfe5d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a0124f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel('/kaggle/input/prepro/manipulated_data.xlsx')\n",
    "\n",
    "# Drop the first column ('Instance') as it's not needed for the heatmap\n",
    "df = df.drop(columns=['Text'])\n",
    "\n",
    "# Calculate the correlation matrix (pairwise frequency of occurrences)\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Create a heatmap using seaborn\n",
    "plt.figure(figsize=(20,12))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Frequency of occurrences between pairs of classes')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442f460c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_tab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f33e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel('/kaggle/input/prepro/manipulated_data.xlsx')\n",
    "\n",
    "# Slice the DataFrame to include only the first 33 classes (columns)\n",
    "df = df.iloc[:, :34]  # Assuming the first column is 'Instance'\n",
    "\n",
    "# Drop the first column ('Instance') as it's not needed for the heatmap\n",
    "df = df.drop(columns=['Text'])\n",
    "\n",
    "# Calculate the correlation matrix (pairwise frequency of occurrences)\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Create a heatmap using seaborn\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Frequency of occurrences between pairs of classes (first 33 classes)')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0575e8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel('/kaggle/input/prepro/manipulated_data.xlsx')\n",
    "\n",
    "# Slice the DataFrame to include only the first 33 classes (columns)\n",
    "df = df.iloc[:, :34]  # Assuming the first column is 'Instance'\n",
    "\n",
    "# Drop the first column ('Instance') as it's not needed for the heatmap\n",
    "df = df.drop(columns=['Text'])\n",
    "df = df.drop(columns=['vyadhi - disease (sickness)'])\n",
    "df = df.drop(columns=['apasmara - forgetfulness (epilepsy/dementedness)'])\n",
    "\n",
    "\n",
    "# Calculate the correlation matrix (pairwise frequency of occurrences)\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "# Create a heatmap using seaborn\n",
    "plt.figure(figsize=(20, 20))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Frequency of occurrences between pairs of classes (first 33 classes)')\n",
    "plt.xlabel('Classes')\n",
    "plt.ylabel('Classes')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7931b716",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53627c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel('/kaggle/input/prepro/manipulated_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8594186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adea1c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers[torch] -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "661cb377",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T15:54:13.950612Z",
     "iopub.status.busy": "2024-03-04T15:54:13.950269Z",
     "iopub.status.idle": "2024-03-04T15:54:41.253812Z",
     "shell.execute_reply": "2024-03-04T15:54:41.252925Z",
     "shell.execute_reply.started": "2024-03-04T15:54:13.950586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\n",
      "Collecting pyarrow>=12.0.0 (from datasets)\n",
      "  Downloading pyarrow-15.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\n",
      "Requirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.20.3)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-15.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (38.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m41.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Installing collected packages: pyarrow-hotfix, pyarrow, datasets\n",
      "  Attempting uninstall: pyarrow\n",
      "    Found existing installation: pyarrow 11.0.0\n",
      "    Uninstalling pyarrow-11.0.0:\n",
      "      Successfully uninstalled pyarrow-11.0.0\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.1.0\n",
      "    Uninstalling datasets-2.1.0:\n",
      "      Successfully uninstalled datasets-2.1.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "cudf 23.8.0 requires cubinlinker, which is not installed.\n",
      "cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "cudf 23.8.0 requires ptxcompiler, which is not installed.\n",
      "cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "dask-cudf 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\n",
      "apache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\n",
      "apache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\n",
      "apache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 15.0.0 which is incompatible.\n",
      "beatrix-jupyterlab 2023.128.151533 requires jupyterlab~=3.6.0, but you have jupyterlab 4.1.2 which is incompatible.\n",
      "cudf 23.8.0 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.3.0 which is incompatible.\n",
      "cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\n",
      "cudf 23.8.0 requires protobuf<5,>=4.21, but you have protobuf 3.20.3 which is incompatible.\n",
      "cudf 23.8.0 requires pyarrow==11.*, but you have pyarrow 15.0.0 which is incompatible.\n",
      "cuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\n",
      "dask-cudf 23.8.0 requires dask==2023.7.1, but you have dask 2024.2.0 which is incompatible.\n",
      "dask-cudf 23.8.0 requires pandas<1.6.0dev0,>=1.3, but you have pandas 2.1.4 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-2.18.0 pyarrow-15.0.0 pyarrow-hotfix-0.6\n"
     ]
    }
   ],
   "source": [
    "!pip install -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43fefb5f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T15:55:44.403124Z",
     "iopub.status.busy": "2024-03-04T15:55:44.402729Z",
     "iopub.status.idle": "2024-03-04T15:55:46.764471Z",
     "shell.execute_reply": "2024-03-04T15:55:46.763709Z",
     "shell.execute_reply.started": "2024-03-04T15:55:44.403094Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64f76371e1c44f49f6bdccef09067e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/109 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 375k/375k [00:00<00:00, 3.59MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6925772dfe884320bf35edc61e449fe3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Hemanth-Sai/Sentiments\",split='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d4ee515",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T15:56:01.767923Z",
     "iopub.status.busy": "2024-03-04T15:56:01.766887Z",
     "iopub.status.idle": "2024-03-04T15:56:01.774483Z",
     "shell.execute_reply": "2024-03-04T15:56:01.773565Z",
     "shell.execute_reply.started": "2024-03-04T15:56:01.767890Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Text', 'nirveda - weeping, sighing,indifference,dicouragement', 'glani - guilty', 'sanka - doubt (apprehension)', 'asuya/irsya - jealousy (envy)', 'mada - madness (intoxication)', 'srama - fatigue', 'alasya/alasata - laziness,sitting idle (unwililng to work)', 'dainya - meekness (depression),(despair)', 'cinta - contemplation (anxiety/reflection)', 'moha - bewilderment,[a feeling of being perplexed and confused] (distraction)', 'smrti - rememberance (recollection)', 'dhriti - forbearance,indifference abstenance (equanimity)', 'vrida - shame', 'capalya/capalatha/capala - impudence [rude behavior that does not show respect for others] (unsteadiness)', 'harsa - jubiliation,enjoyment (joy)', 'avega - intense emotion (agitation/flurry)', 'jadya/jadatha - invalidity,looking with steadfast gaze,unable to think properly', 'garva - pride', 'visada - moroseness, sad [quality of being unhappy, annoyed, and unwilling to speak or smile]', 'autsukya - eagerness (impatience/longing)', 'nidra - sleep (drowsiness)', 'apasmara - forgetfulness (epilepsy/dementedness)', 'supti/supta - deep sleep (dreaming)', 'prabodha/vibodha - awakening', 'amarsa - impatience of opposition', 'avahittha - concealment (hiding of true feelings)', 'augrya/ugrata - violence,battle (cruelity/sterness)', 'mati - attention,instructing pupils (resolve)', 'vyadhi - disease (sickness)', 'unmada - craziness (insanity/madness)', 'mriti/marana - death', 'trasa - shock,fear (fright/alarm)', 'vitarka - argument (doubt)', 'utsuka - restless/anxious', 'tarka -deliberation [long and careful consideration or discussion]', 'rati - romantic', 'lajja - shy', 'marsa - patience', 'tyaga - sacrifice', 'vimochana - releif', 'utsaha - hyped/enthused', 'shraddhaadaya - confidence,trust', 'krodha - anger', 'karuna - pity,kind', 'veera - royality,valour,greatness', 'shanta - serene,peaceful,pleasant', 'vismaya - exaggeration/wonder/surprise/pride/doubt', 'bhakti - devotion', 'no emotion'],\n",
       "    num_rows: 1031\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16ec42b8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T15:56:04.856687Z",
     "iopub.status.busy": "2024-03-04T15:56:04.855850Z",
     "iopub.status.idle": "2024-03-04T15:56:04.878314Z",
     "shell.execute_reply": "2024-03-04T15:56:04.877443Z",
     "shell.execute_reply.started": "2024-03-04T15:56:04.856655Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset=dataset.train_test_split(train_size=0.8,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95f9d91b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T15:56:05.914591Z",
     "iopub.status.busy": "2024-03-04T15:56:05.913791Z",
     "iopub.status.idle": "2024-03-04T15:56:05.919856Z",
     "shell.execute_reply": "2024-03-04T15:56:05.919190Z",
     "shell.execute_reply.started": "2024-03-04T15:56:05.914558Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Text', 'nirveda - weeping, sighing,indifference,dicouragement', 'glani - guilty', 'sanka - doubt (apprehension)', 'asuya/irsya - jealousy (envy)', 'mada - madness (intoxication)', 'srama - fatigue', 'alasya/alasata - laziness,sitting idle (unwililng to work)', 'dainya - meekness (depression),(despair)', 'cinta - contemplation (anxiety/reflection)', 'moha - bewilderment,[a feeling of being perplexed and confused] (distraction)', 'smrti - rememberance (recollection)', 'dhriti - forbearance,indifference abstenance (equanimity)', 'vrida - shame', 'capalya/capalatha/capala - impudence [rude behavior that does not show respect for others] (unsteadiness)', 'harsa - jubiliation,enjoyment (joy)', 'avega - intense emotion (agitation/flurry)', 'jadya/jadatha - invalidity,looking with steadfast gaze,unable to think properly', 'garva - pride', 'visada - moroseness, sad [quality of being unhappy, annoyed, and unwilling to speak or smile]', 'autsukya - eagerness (impatience/longing)', 'nidra - sleep (drowsiness)', 'apasmara - forgetfulness (epilepsy/dementedness)', 'supti/supta - deep sleep (dreaming)', 'prabodha/vibodha - awakening', 'amarsa - impatience of opposition', 'avahittha - concealment (hiding of true feelings)', 'augrya/ugrata - violence,battle (cruelity/sterness)', 'mati - attention,instructing pupils (resolve)', 'vyadhi - disease (sickness)', 'unmada - craziness (insanity/madness)', 'mriti/marana - death', 'trasa - shock,fear (fright/alarm)', 'vitarka - argument (doubt)', 'utsuka - restless/anxious', 'tarka -deliberation [long and careful consideration or discussion]', 'rati - romantic', 'lajja - shy', 'marsa - patience', 'tyaga - sacrifice', 'vimochana - releif', 'utsaha - hyped/enthused', 'shraddhaadaya - confidence,trust', 'krodha - anger', 'karuna - pity,kind', 'veera - royality,valour,greatness', 'shanta - serene,peaceful,pleasant', 'vismaya - exaggeration/wonder/surprise/pride/doubt', 'bhakti - devotion', 'no emotion'],\n",
       "        num_rows: 824\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Text', 'nirveda - weeping, sighing,indifference,dicouragement', 'glani - guilty', 'sanka - doubt (apprehension)', 'asuya/irsya - jealousy (envy)', 'mada - madness (intoxication)', 'srama - fatigue', 'alasya/alasata - laziness,sitting idle (unwililng to work)', 'dainya - meekness (depression),(despair)', 'cinta - contemplation (anxiety/reflection)', 'moha - bewilderment,[a feeling of being perplexed and confused] (distraction)', 'smrti - rememberance (recollection)', 'dhriti - forbearance,indifference abstenance (equanimity)', 'vrida - shame', 'capalya/capalatha/capala - impudence [rude behavior that does not show respect for others] (unsteadiness)', 'harsa - jubiliation,enjoyment (joy)', 'avega - intense emotion (agitation/flurry)', 'jadya/jadatha - invalidity,looking with steadfast gaze,unable to think properly', 'garva - pride', 'visada - moroseness, sad [quality of being unhappy, annoyed, and unwilling to speak or smile]', 'autsukya - eagerness (impatience/longing)', 'nidra - sleep (drowsiness)', 'apasmara - forgetfulness (epilepsy/dementedness)', 'supti/supta - deep sleep (dreaming)', 'prabodha/vibodha - awakening', 'amarsa - impatience of opposition', 'avahittha - concealment (hiding of true feelings)', 'augrya/ugrata - violence,battle (cruelity/sterness)', 'mati - attention,instructing pupils (resolve)', 'vyadhi - disease (sickness)', 'unmada - craziness (insanity/madness)', 'mriti/marana - death', 'trasa - shock,fear (fright/alarm)', 'vitarka - argument (doubt)', 'utsuka - restless/anxious', 'tarka -deliberation [long and careful consideration or discussion]', 'rati - romantic', 'lajja - shy', 'marsa - patience', 'tyaga - sacrifice', 'vimochana - releif', 'utsaha - hyped/enthused', 'shraddhaadaya - confidence,trust', 'krodha - anger', 'karuna - pity,kind', 'veera - royality,valour,greatness', 'shanta - serene,peaceful,pleasant', 'vismaya - exaggeration/wonder/surprise/pride/doubt', 'bhakti - devotion', 'no emotion'],\n",
       "        num_rows: 207\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f558884",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T15:56:07.183477Z",
     "iopub.status.busy": "2024-03-04T15:56:07.182877Z",
     "iopub.status.idle": "2024-03-04T15:56:07.205250Z",
     "shell.execute_reply": "2024-03-04T15:56:07.204516Z",
     "shell.execute_reply.started": "2024-03-04T15:56:07.183447Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_val=dataset['test'].train_test_split(train_size=0.5,shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "86466b9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T15:56:07.956771Z",
     "iopub.status.busy": "2024-03-04T15:56:07.956444Z",
     "iopub.status.idle": "2024-03-04T15:56:07.962809Z",
     "shell.execute_reply": "2024-03-04T15:56:07.961818Z",
     "shell.execute_reply.started": "2024-03-04T15:56:07.956747Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Text', 'nirveda - weeping, sighing,indifference,dicouragement', 'glani - guilty', 'sanka - doubt (apprehension)', 'asuya/irsya - jealousy (envy)', 'mada - madness (intoxication)', 'srama - fatigue', 'alasya/alasata - laziness,sitting idle (unwililng to work)', 'dainya - meekness (depression),(despair)', 'cinta - contemplation (anxiety/reflection)', 'moha - bewilderment,[a feeling of being perplexed and confused] (distraction)', 'smrti - rememberance (recollection)', 'dhriti - forbearance,indifference abstenance (equanimity)', 'vrida - shame', 'capalya/capalatha/capala - impudence [rude behavior that does not show respect for others] (unsteadiness)', 'harsa - jubiliation,enjoyment (joy)', 'avega - intense emotion (agitation/flurry)', 'jadya/jadatha - invalidity,looking with steadfast gaze,unable to think properly', 'garva - pride', 'visada - moroseness, sad [quality of being unhappy, annoyed, and unwilling to speak or smile]', 'autsukya - eagerness (impatience/longing)', 'nidra - sleep (drowsiness)', 'apasmara - forgetfulness (epilepsy/dementedness)', 'supti/supta - deep sleep (dreaming)', 'prabodha/vibodha - awakening', 'amarsa - impatience of opposition', 'avahittha - concealment (hiding of true feelings)', 'augrya/ugrata - violence,battle (cruelity/sterness)', 'mati - attention,instructing pupils (resolve)', 'vyadhi - disease (sickness)', 'unmada - craziness (insanity/madness)', 'mriti/marana - death', 'trasa - shock,fear (fright/alarm)', 'vitarka - argument (doubt)', 'utsuka - restless/anxious', 'tarka -deliberation [long and careful consideration or discussion]', 'rati - romantic', 'lajja - shy', 'marsa - patience', 'tyaga - sacrifice', 'vimochana - releif', 'utsaha - hyped/enthused', 'shraddhaadaya - confidence,trust', 'krodha - anger', 'karuna - pity,kind', 'veera - royality,valour,greatness', 'shanta - serene,peaceful,pleasant', 'vismaya - exaggeration/wonder/surprise/pride/doubt', 'bhakti - devotion', 'no emotion'],\n",
       "        num_rows: 103\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Text', 'nirveda - weeping, sighing,indifference,dicouragement', 'glani - guilty', 'sanka - doubt (apprehension)', 'asuya/irsya - jealousy (envy)', 'mada - madness (intoxication)', 'srama - fatigue', 'alasya/alasata - laziness,sitting idle (unwililng to work)', 'dainya - meekness (depression),(despair)', 'cinta - contemplation (anxiety/reflection)', 'moha - bewilderment,[a feeling of being perplexed and confused] (distraction)', 'smrti - rememberance (recollection)', 'dhriti - forbearance,indifference abstenance (equanimity)', 'vrida - shame', 'capalya/capalatha/capala - impudence [rude behavior that does not show respect for others] (unsteadiness)', 'harsa - jubiliation,enjoyment (joy)', 'avega - intense emotion (agitation/flurry)', 'jadya/jadatha - invalidity,looking with steadfast gaze,unable to think properly', 'garva - pride', 'visada - moroseness, sad [quality of being unhappy, annoyed, and unwilling to speak or smile]', 'autsukya - eagerness (impatience/longing)', 'nidra - sleep (drowsiness)', 'apasmara - forgetfulness (epilepsy/dementedness)', 'supti/supta - deep sleep (dreaming)', 'prabodha/vibodha - awakening', 'amarsa - impatience of opposition', 'avahittha - concealment (hiding of true feelings)', 'augrya/ugrata - violence,battle (cruelity/sterness)', 'mati - attention,instructing pupils (resolve)', 'vyadhi - disease (sickness)', 'unmada - craziness (insanity/madness)', 'mriti/marana - death', 'trasa - shock,fear (fright/alarm)', 'vitarka - argument (doubt)', 'utsuka - restless/anxious', 'tarka -deliberation [long and careful consideration or discussion]', 'rati - romantic', 'lajja - shy', 'marsa - patience', 'tyaga - sacrifice', 'vimochana - releif', 'utsaha - hyped/enthused', 'shraddhaadaya - confidence,trust', 'krodha - anger', 'karuna - pity,kind', 'veera - royality,valour,greatness', 'shanta - serene,peaceful,pleasant', 'vismaya - exaggeration/wonder/surprise/pride/doubt', 'bhakti - devotion', 'no emotion'],\n",
       "        num_rows: 104\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6270bcd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T15:56:24.686573Z",
     "iopub.status.busy": "2024-03-04T15:56:24.685856Z",
     "iopub.status.idle": "2024-03-04T15:56:24.694751Z",
     "shell.execute_reply": "2024-03-04T15:56:24.693925Z",
     "shell.execute_reply.started": "2024-03-04T15:56:24.686542Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Text': 'वागर्थाविवसंपृक्तौवागर्थप्रतिपत्तये।जगतःपितरौवन्देपार्वतीपरमेश्वरौ',\n",
       " 'nirveda - weeping, sighing,indifference,dicouragement': 0,\n",
       " 'glani - guilty': 0,\n",
       " 'sanka - doubt (apprehension)': 0,\n",
       " 'asuya/irsya - jealousy (envy)': 0,\n",
       " 'mada - madness (intoxication)': 0,\n",
       " 'srama - fatigue': 0,\n",
       " 'alasya/alasata - laziness,sitting idle (unwililng to work)': 0,\n",
       " 'dainya - meekness (depression),(despair)': 0,\n",
       " 'cinta - contemplation (anxiety/reflection)': 0,\n",
       " 'moha - bewilderment,[a feeling of being perplexed and confused] (distraction)': 0,\n",
       " 'smrti - rememberance (recollection)': 0,\n",
       " 'dhriti - forbearance,indifference abstenance (equanimity)': 0,\n",
       " 'vrida - shame': 0,\n",
       " 'capalya/capalatha/capala - impudence [rude behavior that does not show respect for others] (unsteadiness)': 0,\n",
       " 'harsa - jubiliation,enjoyment (joy)': 0,\n",
       " 'avega - intense emotion (agitation/flurry)': 0,\n",
       " 'jadya/jadatha - invalidity,looking with steadfast gaze,unable to think properly': 0,\n",
       " 'garva - pride': 0,\n",
       " 'visada - moroseness, sad [quality of being unhappy, annoyed, and unwilling to speak or smile]': 0,\n",
       " 'autsukya - eagerness (impatience/longing)': 0,\n",
       " 'nidra - sleep (drowsiness)': 0,\n",
       " 'apasmara - forgetfulness (epilepsy/dementedness)': 0,\n",
       " 'supti/supta - deep sleep (dreaming)': 0,\n",
       " 'prabodha/vibodha - awakening': 0,\n",
       " 'amarsa - impatience of opposition': 0,\n",
       " 'avahittha - concealment (hiding of true feelings)': 0,\n",
       " 'augrya/ugrata - violence,battle (cruelity/sterness)': 0,\n",
       " 'mati - attention,instructing pupils (resolve)': 0,\n",
       " 'vyadhi - disease (sickness)': 0,\n",
       " 'unmada - craziness (insanity/madness)': 0,\n",
       " 'mriti/marana - death': 0,\n",
       " 'trasa - shock,fear (fright/alarm)': 0,\n",
       " 'vitarka - argument (doubt)': 0,\n",
       " 'utsuka - restless/anxious': 0,\n",
       " 'tarka -deliberation [long and careful consideration or discussion]': 0,\n",
       " 'rati - romantic': 0,\n",
       " 'lajja - shy': 0,\n",
       " 'marsa - patience': 0,\n",
       " 'tyaga - sacrifice': 0,\n",
       " 'vimochana - releif': 0,\n",
       " 'utsaha - hyped/enthused': 0,\n",
       " 'shraddhaadaya - confidence,trust': 0,\n",
       " 'krodha - anger': 0,\n",
       " 'karuna - pity,kind': 0,\n",
       " 'veera - royality,valour,greatness': 0,\n",
       " 'shanta - serene,peaceful,pleasant': 0,\n",
       " 'vismaya - exaggeration/wonder/surprise/pride/doubt': 0,\n",
       " 'bhakti - devotion': 1,\n",
       " 'no emotion': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = dataset['train'][0]\n",
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "721ddf3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T04:03:12.413613Z",
     "iopub.status.busy": "2024-03-05T04:03:12.413266Z",
     "iopub.status.idle": "2024-03-05T04:03:12.729553Z",
     "shell.execute_reply": "2024-03-05T04:03:12.728750Z",
     "shell.execute_reply.started": "2024-03-05T04:03:12.413587Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6cc550a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T05:01:20.702273Z",
     "iopub.status.busy": "2024-03-05T05:01:20.701482Z",
     "iopub.status.idle": "2024-03-05T05:01:21.669443Z",
     "shell.execute_reply": "2024-03-05T05:01:21.668272Z",
     "shell.execute_reply.started": "2024-03-05T05:01:20.702241Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Read the Excel file into a DataFrame\n",
    "df = pd.read_excel('/kaggle/input/prepro/manipulated_data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e65946a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T04:03:14.311466Z",
     "iopub.status.busy": "2024-03-05T04:03:14.310843Z",
     "iopub.status.idle": "2024-03-05T04:03:14.315527Z",
     "shell.execute_reply": "2024-03-05T04:03:14.314622Z",
     "shell.execute_reply.started": "2024-03-05T04:03:14.311428Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a list of columns that should not be chosen as label columns\n",
    "not_chosen_columns = ['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "34a8de31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T04:03:14.316812Z",
     "iopub.status.busy": "2024-03-05T04:03:14.316546Z",
     "iopub.status.idle": "2024-03-05T04:03:14.326531Z",
     "shell.execute_reply": "2024-03-05T04:03:14.325706Z",
     "shell.execute_reply.started": "2024-03-05T04:03:14.316790Z"
    }
   },
   "outputs": [],
   "source": [
    "# Select label columns that are not in the list of not chosen columns\n",
    "label_columns = [col for col in df.columns if col not in not_chosen_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e49bea7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T04:03:14.328895Z",
     "iopub.status.busy": "2024-03-05T04:03:14.328391Z",
     "iopub.status.idle": "2024-03-05T04:03:14.338693Z",
     "shell.execute_reply": "2024-03-05T04:03:14.337909Z",
     "shell.execute_reply.started": "2024-03-05T04:03:14.328862Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "117a1069",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T05:01:22.931431Z",
     "iopub.status.busy": "2024-03-05T05:01:22.930692Z",
     "iopub.status.idle": "2024-03-05T05:01:22.941221Z",
     "shell.execute_reply": "2024-03-05T05:01:22.940114Z",
     "shell.execute_reply.started": "2024-03-05T05:01:22.931398Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in training set: 824\n",
      "Number of rows in test set: 207\n"
     ]
    }
   ],
   "source": [
    "test_split = 0.2\n",
    "\n",
    "# Initial train and test split.\n",
    "train_df, test_df = train_test_split(\n",
    "    df,\n",
    "    test_size=test_split,\n",
    ")\n",
    "print(f\"Number of rows in training set: {len(train_df)}\")\n",
    "print(f\"Number of rows in test set: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0cd2942f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T05:01:27.769342Z",
     "iopub.status.busy": "2024-03-05T05:01:27.768840Z",
     "iopub.status.idle": "2024-03-05T05:01:27.778606Z",
     "shell.execute_reply": "2024-03-05T05:01:27.777435Z",
     "shell.execute_reply.started": "2024-03-05T05:01:27.769308Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows in training set: 103\n",
      "Number of rows in test set: 104\n"
     ]
    }
   ],
   "source": [
    "test_split = 0.5\n",
    "\n",
    "# Initial train and test split.\n",
    "test_df, eval_df = train_test_split(\n",
    "    test_df,\n",
    "    test_size=test_split,\n",
    ")\n",
    "print(f\"Number of rows in training set: {len(test_df)}\")\n",
    "print(f\"Number of rows in test set: {len(eval_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d130cc07",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T05:01:51.926891Z",
     "iopub.status.busy": "2024-03-05T05:01:51.926166Z",
     "iopub.status.idle": "2024-03-05T05:01:51.934905Z",
     "shell.execute_reply": "2024-03-05T05:01:51.933733Z",
     "shell.execute_reply.started": "2024-03-05T05:01:51.926852Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a new DataFrame containing only the selected label columns\n",
    "df_labels_train = train_df[label_columns]\n",
    "df_labels_eval = eval_df[label_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e79ec5df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T05:02:13.894187Z",
     "iopub.status.busy": "2024-03-05T05:02:13.893419Z",
     "iopub.status.idle": "2024-03-05T05:02:13.903421Z",
     "shell.execute_reply": "2024-03-05T05:02:13.902117Z",
     "shell.execute_reply.started": "2024-03-05T05:02:13.894154Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert the label columns to lists for each row\n",
    "labels_list_train = df_labels_train.values.tolist()\n",
    "labels_list_eval = df_labels_eval.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "bc793d46",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T05:02:23.673273Z",
     "iopub.status.busy": "2024-03-05T05:02:23.672445Z",
     "iopub.status.idle": "2024-03-05T05:02:23.691978Z",
     "shell.execute_reply": "2024-03-05T05:02:23.690565Z",
     "shell.execute_reply.started": "2024-03-05T05:02:23.673230Z"
    }
   },
   "outputs": [],
   "source": [
    "labels_list_train = [[float(label) for label in labels] for labels in labels_list_train]\n",
    "labels_list_eval = [[float(label) for label in labels] for labels in labels_list_eval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7e8e0892",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T05:02:25.720214Z",
     "iopub.status.busy": "2024-03-05T05:02:25.719358Z",
     "iopub.status.idle": "2024-03-05T05:02:25.726512Z",
     "shell.execute_reply": "2024-03-05T05:02:25.725504Z",
     "shell.execute_reply.started": "2024-03-05T05:02:25.720178Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, AutoTokenizer, AutoModelForSequenceClassification, Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b43a0739",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T05:02:40.029977Z",
     "iopub.status.busy": "2024-03-05T05:02:40.029599Z",
     "iopub.status.idle": "2024-03-05T05:02:40.214381Z",
     "shell.execute_reply": "2024-03-05T05:02:40.213216Z",
     "shell.execute_reply.started": "2024-03-05T05:02:40.029947Z"
    }
   },
   "outputs": [],
   "source": [
    "train_texts = train_df['Text'].tolist()\n",
    "train_labels = labels_list_train\n",
    "\n",
    "eval_texts = eval_df['Text'].tolist()\n",
    "eval_labels = labels_list_eval\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('sampathlonka/San-BERT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a2d3f2e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T05:02:47.307300Z",
     "iopub.status.busy": "2024-03-05T05:02:47.306600Z",
     "iopub.status.idle": "2024-03-05T05:02:47.453032Z",
     "shell.execute_reply": "2024-03-05T05:02:47.451922Z",
     "shell.execute_reply.started": "2024-03-05T05:02:47.307266Z"
    }
   },
   "outputs": [],
   "source": [
    "train_encodings = tokenizer(train_texts, padding=\"max_length\", truncation=True, max_length=512)\n",
    "eval_encodings = tokenizer(eval_texts, padding=\"max_length\", truncation=True, max_length=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3d6ac59f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T05:02:47.765406Z",
     "iopub.status.busy": "2024-03-05T05:02:47.764432Z",
     "iopub.status.idle": "2024-03-05T05:02:47.772181Z",
     "shell.execute_reply": "2024-03-05T05:02:47.770194Z",
     "shell.execute_reply.started": "2024-03-05T05:02:47.765370Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3359e4a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T05:02:49.876986Z",
     "iopub.status.busy": "2024-03-05T05:02:49.876109Z",
     "iopub.status.idle": "2024-03-05T05:02:49.884889Z",
     "shell.execute_reply": "2024-03-05T05:02:49.883950Z",
     "shell.execute_reply.started": "2024-03-05T05:02:49.876954Z"
    }
   },
   "outputs": [],
   "source": [
    "class TextClassifierDataset(Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
    "        return item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c7d3863c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T05:02:53.409978Z",
     "iopub.status.busy": "2024-03-05T05:02:53.409040Z",
     "iopub.status.idle": "2024-03-05T05:02:53.415439Z",
     "shell.execute_reply": "2024-03-05T05:02:53.414467Z",
     "shell.execute_reply.started": "2024-03-05T05:02:53.409946Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = TextClassifierDataset(train_encodings, train_labels)\n",
    "eval_dataset = TextClassifierDataset(eval_encodings, eval_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d5391f4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T05:02:53.819697Z",
     "iopub.status.busy": "2024-03-05T05:02:53.818821Z",
     "iopub.status.idle": "2024-03-05T05:02:54.190564Z",
     "shell.execute_reply": "2024-03-05T05:02:54.189243Z",
     "shell.execute_reply.started": "2024-03-05T05:02:53.819655Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at sampathlonka/San-BERT and are newly initialized: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"sampathlonka/San-BERT\",\n",
    "    problem_type=\"multi_label_classification\",\n",
    "    num_labels=49\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "180c08f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T05:02:58.676108Z",
     "iopub.status.busy": "2024-03-05T05:02:58.675716Z",
     "iopub.status.idle": "2024-03-05T05:02:58.806858Z",
     "shell.execute_reply": "2024-03-05T05:02:58.805760Z",
     "shell.execute_reply.started": "2024-03-05T05:02:58.676073Z"
    }
   },
   "outputs": [],
   "source": [
    "training_arguments = TrainingArguments(\n",
    "    output_dir=\"Trail\",\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=10,\n",
    "    save_total_limit=2,\n",
    "    save_strategy=\"epoch\",\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_arguments,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    tokenizer=tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d6dffcda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T05:02:58.976962Z",
     "iopub.status.busy": "2024-03-05T05:02:58.976258Z",
     "iopub.status.idle": "2024-03-05T05:02:58.982407Z",
     "shell.execute_reply": "2024-03-05T05:02:58.981282Z",
     "shell.execute_reply.started": "2024-03-05T05:02:58.976927Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "498500cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T05:03:02.001034Z",
     "iopub.status.busy": "2024-03-05T05:03:02.000397Z",
     "iopub.status.idle": "2024-03-05T05:11:57.342508Z",
     "shell.execute_reply": "2024-03-05T05:11:57.341592Z",
     "shell.execute_reply.started": "2024-03-05T05:03:02.000999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2060' max='2060' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2060/2060 08:54, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.129316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.128363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.139100</td>\n",
       "      <td>0.127126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.139100</td>\n",
       "      <td>0.127076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.117600</td>\n",
       "      <td>0.127298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.117600</td>\n",
       "      <td>0.127174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.117600</td>\n",
       "      <td>0.127035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.127137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.127112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.116300</td>\n",
       "      <td>0.127087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory Trail/checkpoint-1854 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n",
      "Checkpoint destination directory Trail/checkpoint-2060 already exists and is non-empty. Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=2060, training_loss=0.12223589744382692, metrics={'train_runtime': 534.7404, 'train_samples_per_second': 15.409, 'train_steps_per_second': 3.852, 'total_flos': 2168949994045440.0, 'train_loss': 0.12223589744382692, 'epoch': 10.0})"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "82cf96cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T05:12:13.619215Z",
     "iopub.status.busy": "2024-03-05T05:12:13.618828Z",
     "iopub.status.idle": "2024-03-05T05:12:13.657524Z",
     "shell.execute_reply": "2024-03-05T05:12:13.656277Z",
     "shell.execute_reply.started": "2024-03-05T05:12:13.619183Z"
    }
   },
   "outputs": [],
   "source": [
    "df_labels_test = test_df[label_columns]\n",
    "labels_list_test = df_labels_test.values.tolist()\n",
    "labels_list_test = [[float(label) for label in labels] for labels in labels_list_test]\n",
    "test_texts = test_df['Text'].tolist()\n",
    "test_labels = labels_list_test\n",
    "test_encodings = tokenizer(test_texts, padding=\"max_length\", truncation=True, max_length=512)\n",
    "test_dataset = TextClassifierDataset(test_encodings, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6f62ed7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-05T05:12:14.882264Z",
     "iopub.status.busy": "2024-03-05T05:12:14.881807Z",
     "iopub.status.idle": "2024-03-05T05:12:16.801641Z",
     "shell.execute_reply": "2024-03-05T05:12:16.800537Z",
     "shell.execute_reply.started": "2024-03-05T05:12:14.882235Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='26' max='26' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [26/26 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.11658675968647003,\n",
       " 'eval_runtime': 1.9098,\n",
       " 'eval_samples_per_second': 53.931,\n",
       " 'eval_steps_per_second': 13.614,\n",
       " 'epoch': 10.0}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "80cf1e89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T16:31:41.631761Z",
     "iopub.status.busy": "2024-03-04T16:31:41.630798Z",
     "iopub.status.idle": "2024-03-04T16:31:41.752394Z",
     "shell.execute_reply": "2024-03-04T16:31:41.751202Z",
     "shell.execute_reply.started": "2024-03-04T16:31:41.631726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to /root/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "login(\"************************************\",write_permission=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "84610f02",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T16:31:44.071924Z",
     "iopub.status.busy": "2024-03-04T16:31:44.071213Z",
     "iopub.status.idle": "2024-03-04T16:32:00.762833Z",
     "shell.execute_reply": "2024-03-04T16:32:00.761720Z",
     "shell.execute_reply.started": "2024-03-04T16:31:44.071895Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f906931e5894bfb9f37e2d4803ce544",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b4555fcf21e405fac915686931fad57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1709549973.7582d9fd9a6c.133.0:   0%|          | 0.00/6.78k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104f8d1fe6e246bf9c19e71f70775bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1709550309.7582d9fd9a6c.133.1:   0%|          | 0.00/6.78k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423ad76b51924ef3bf2d8c7e447f8b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1709550376.7582d9fd9a6c.133.2:   0%|          | 0.00/6.78k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3f5a9ed708487e93e554b03374f7bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Upload 8 LFS files:   0%|          | 0/8 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ef0e5617c048288ae4870f1f515c32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1709550470.7582d9fd9a6c.133.3:   0%|          | 0.00/6.78k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "310270963b334f489d0c32c0e8506ff6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1709568888.8de846a36389.35.0:   0%|          | 0.00/14.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b5647242964b438dd91cc991640fa1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "events.out.tfevents.1709569279.8de846a36389.35.1:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b7f6df5b9545d3ab48ec1f65864cb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "training_args.bin:   0%|          | 0.00/4.86k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Hemanth-Sai/Trail/commit/4d7fee63c758f70860ef52d094f7a9b660f22ece', commit_message='End of training', commit_description='', oid='4d7fee63c758f70860ef52d094f7a9b660f22ece', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.push_to_hub()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "60dc45a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-04T16:33:45.259790Z",
     "iopub.status.busy": "2024-03-04T16:33:45.258900Z",
     "iopub.status.idle": "2024-03-04T16:33:46.415671Z",
     "shell.execute_reply": "2024-03-04T16:33:46.414605Z",
     "shell.execute_reply.started": "2024-03-04T16:33:45.259758Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f615d6713ef041c3ac22e1a710fe8b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/1.71k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Hemanth-Sai/Trail/commit/9a79c6dccdda1b818675bac921cf72a84e4c6afa', commit_message='Upload tokenizer', commit_description='', oid='9a79c6dccdda1b818675bac921cf72a84e4c6afa', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.push_to_hub(\"Hemanth-Sai/Trail\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4535494,
     "sourceId": 7756334,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
